```python

```
![alt text](https://github.com/eperrier/QDataSet/blob/main/qdataset_clean.png?raw=true)

# QDataSet: Quantum Datasets for Machine Learning

## Overview 
This is the repository for the QDataSet introduced in [*QDataset: Quantum Datasets for Machine Learning* by Perrier, Youssry & Ferrie (2021)](https://arxiv.org/abs/2108.06661), a quantum dataset designed specifically to facilitate the training and development of QML algorithms. The QDataSet comprises 52 high-quality publicly available datasets derived from simulations of one- and two-qubit systems evolving in the presence and/or absence of noise.

The datasets are structured to provide a wealth of information to enable machine learning practitioners to use the QDataSet to solve problems in applied quantum computation, such as quantum control, quantum spectroscopy and tomography. Accompanying the datasets in this repository are a set of workbooks demonstrating the use of the QDataSet in a range of optimisation contexts.

### Link to QDataSet

The links to the QDataSet is here: [QDataSet Cloudstor Link](https://cloudstor.aarnet.edu.au/plus/s/rxYKXBS7Tq0kB8o). More details on cloud storage are included below.

### Links to examples notebooks

Example notebooks can be found in the 'examples' subfolder in this repository.

### Link to QDataSet simulation code

Links to the QDataSet simulation code can be found in the 'simulation' subfolder in this repository.

### Citing this repository and paper

Citation of the paper:

Perrier, E., Youssry, A. & Ferrie, C. QDataset: Quantum Datasets for Machine Learning. (2021). 	arXiv:2108.06661 [quant-ph].

Citation of this repository is recommended in the following formats (see the 'Cite this repository' link to the right):

Perrier E., Youssry A., Ferrie C. (2021). QDataSet: Quantum Datasets for Machine Learning (version 1.0.0). DOI: https://doi.org/10.5281/zenodo.5202814

For Bibtex:

@misc{Perrier_QDataSet_Quantum_Datasets_2021,
author = {Perrier, Elija and Youssry, Akram and Ferrie, Chris},
doi = {10.5281/zenodo.5202814},
month = {8},
title = {QDataSet: Quantum Datasets for Machine Learning},
url = {https://github.com/eperrier/QDataSet},
year = {2021}
}

## Summary
The QDataSet comprises 52 datasets based on simulations of one- and two-qubit systems evolving in the presence and/or absence of noise subject to a variety of controls. It has been developed to provide a large-scale set of datasets for the training, benchmarking and competitive development of classical and quantum algorithms for common tasks in quantum sciences, including quantum control, quantum tomography and noise spectroscopy. 

It has been generated using customised code drawing upon base-level Python packages in order to facilitate interoperability and portability across common machine learning and quantum programming platforms. Each dataset consists of 10,000 samples which in turn comprise a range of data relevant to the training of machine learning algorithms for solving optimisation problems. 

The data includes a range of information (stored in list, matrix or tensor format) regarding quantum systems and their evolution, such as: quantum state vectors, drift and control Hamiltonians and unitaries, Pauli measurement distributions, time series data, pulse sequence data for square and Gaussian pulses and noise and distortion data. The total compressed size of the QDataSet (using Pickle and zip formats) is around 14TB (uncompressed, around 100TB). 

Researchers can use the QDataSet in a variety of ways to design algorithms for solving problems in quantum control, quantum tomography and quantum circuit synthesis, together with algorithms focused on classifying or simulating such data. We also provide working examples of how to use the QDataSet in practice and its use in benchmarking certain algorithms. 

The associated paper provides in-depth detail on the QDataSet for researchers who may be unfamiliar with quantum computing, together with specifications for domain experts within quantum engineering, quantum computation and quantum machine learning.

# Description of datasets

## Dataset categories

The datasets in the QDataSet are set-out in Pickle-compressed lists and dictionaries. A taxonomy of each datasets is included below.

Each dataset can be categorised according to the number of qubits in the system and the noise profile to which the system was subject. [The table below] sets out a summary of such categories. For category 1 of the datasets, we created datasets with noise profiles N1, N2, N3, N4, together with the noiseless case. This gives a total of 5 datasets. 

For category 2,  the noise profiles for the X and Z respectively are chosen to be (N1,N5), (N1,N6), (N3,N6). Together with the noiseless case, this gives a total of 4 datasets. 

For category 3 (two-qubit system), we chose only the 1Z (identity on the first qubit, noise along the z-axis for the second) and Z1 (noise along the z-axis for the first qubit, identity along the second) noise to follow the (N1,N6) profile. This category simulates two individual qubit with correlated noise sources. 

For category 4, we generate the noiseless, (N1,N5), and (N1,N6) for the 1Z and Z1 noise. This gives 3 datasets. Therefore, the total number off datasets at this point is 13. Now, if we include the two types of control waveforms, this gives a total of 26. If we also include the cases of distortion and non-distorted control, then this gives a total of 52 datasets. Comprehensive detail on the noise profiles used to generate the datasets is contained in Appendix of the QDataSet paper.

## Naming convention

We chose a convention for the naming of the dataset to try delivering as much information as possible about the chosen parameters for this particular dataset. The name is partitioned into 6 parts, separated by an underscore sign '\_'. 

* The first part is either the letter 'G' or 'S' to denote whether the control waveform is Gaussian or square. 

* The second part is either '1q' or '2q' to denote the dimensionality of the system. 

* The third part denotes the control Hamiltonian. It is formed by listing down the Pauli operators we are using for the control for each qubit, and we separate between qubit by a hyphen '-'. For example, category 1 datasets will have 'X', while category 4 with have 'IX-XI-XX'. 

* The fourth part is optional and it encodes the noise Hamiltonian following the same convention of the third part. 

* The fifth which is also optional part contains the noise profiles following the same order of operators in the fourth part. If the dataset is for noiseless simulation, the the fourth and fifth parts are not included. 

* The sixth part denotes the presence of control distortions by the letter 'D', otherwise it is empty. 

For example, the dataset 'G\_2q\_IX-XI-XX\_IZ-ZI\_N1-N6' is two qubit, Gaussian pulses with no distortions, local X control on each qubit and an interacting XX control, there local Z-noise on each qubit with profile N1 and N6. Another example the dataset 'S\_1q\_XY\_D', is a single-qubit system with square distorted control pulses along X and Y axis, and there is no noise.

| Category | Qubits | Drift      | Control        | Noise      |
|--------------------|------------------|----------------------|--------------------------|----------------------|
| 1        | 1      | (*z*)      | (*x*)          | (*z*)      |
| 2        | 1      | (*z*)      | (*x*,*y*)        | (*x*,*z*)    |
| 3        | 2      | (*z*1, 1*z*) | (*x*1, 1*x*)     | (*z*1, 1*z*) |
| 4        | 2      | (*z*1, 1*z*) | (*x*1, 1*x*, *xx*) | (*z*1,1*z*) |



## QDataSet Parameters

A dictionary of specifications for each example in the QDataSet is set out in table below. Each of the 10,000 examples in each of the 52 datasets is encoded in one of these dictionaries.


| Item                     | Description                                                                                                                                                                                                                                                                                              |
|---------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| *simulation_parameters* |  *name*: name of the dataset                                                                     |
|  |       *dim*: the dimension 2<sup>*n*</sup> of the Hilbert space for $n$ qubits (dimension 2 for single qubit, 4 for two qubits)                                                                                                                                                                                                                                                                                                                                                                                                             |
|  |       *Ω*: the spectral energy gap                                                                                                                                                                                                                                                                                             |
|  |  *static_operators*: a list of matrices representing the time-independent parts of the Hamiltonian (i.e. drift components)|
|  |  *dynamic_operators*: a list of matrices representing the time-dependent parts of the Hamiltonian (i.e. control components), without the pulses. So, if we have a term *f*(*t*)*σ*<sub>*x*</sub> + *g*(*t*)*σ*<sub>*y*</sub>, this list will be \[*σ*<sub>*x*</sub>,*σ*<sub>*y*</sub>\]|
|  |  *noise_operators*: a list of time-dependent parts of the Hamiltonian that are stochastic (i.e. noise components). so if we have terms like *β*<sub>1</sub>(*t*)*σ*<sub>*z*</sub> + *β*<sub>2</sub>(*t*)*σ*<sub>*y*</sub>, the list will be \[*σ*<sub>*z*</sub>,*σ*<sub>*y*</sub>\]|
|  |  *measurement_operators*: Pauli operators (including identity) (*I*, *σ*<sub>*x*</sub>, *σ*<sub>*y*</sub>, *σ*<sub>*z*</sub>)|
|  |  *initial_states*: the six eigenstates of the Pauli operators|
|  |  *T*: total time (normalised to unity)|
|  |  *num_ex*: number of examples, set to 10,000|
|  |  *batch_size*: size of batch used in data generation (default is 50)|
|  |  *K*: number of randomised pulse sequences in Monte Carlo simulation of noise (set to $K = 2000$)|
|  |  *noise_profile*: N0 to N6 (see paper for detail)|
|  |  *pulse_shape*: Gaussian or Square|
|  |  *num_pulses*: number of pulses per interval|
|  |  *elapsed_time*: time taken to generate the datasets|
| *pulse_parameters*      | The control pulse sequence parameters for the example:                                                                                                                                                                                                                                                            |
| | Square pulses: *A*<sub>*k*</sub> amplitude at time *t*<sub>*k*</sub>|
| | Gaussian pulses: *A*<sub>*k*</sub> (amplitude), *μ* (mean) and $*σ* (standard deviation)|
| *time_range*            | A sequence of time intervals *Δ*(*t*)<sub>*j*</sub> with *j* = 1, ..., *M*                                                                                                                                                                                                                                                      |
| *pulses*                 | Time-domain waveform of the control pulse sequence.                                                                                                                                                                                                                                                               |
| *distorted_pulses*      | Time-domain waveform of the distorted control pulse sequence (if there are no distortions, the waveform will be identical to the undistorted pulses).                                                                                                                                                             |
| *expectations*           | The Pauli expectation values 18 or 52 depending on whether one or two qubits (see above). For each state, the order of measurement is: *σ*<sub>*x*</sub>, *σ*<sub>*y*</sub>, *σ*<sub>*z*</sub> applied to the evolved initial states. As the quantum state is evolving in time, the expectations will range within the interval [1,-1]. |
| *V*<sub>*O*</sub> operator         | The *V*<sub>*O*</sub> operators corresponding to the three Pauli observables, obtained by averaging the operators *W*<sub>*O*</sub> over all noise realizations.                                                                                                                                                                          |
| *noise*                  | Time domain realisations of the relevant noise.                                                                                                                                                                                                                                                                   |
| *H*<sub>0</sub>                  | The system Hamiltonian *H*<sub>0</sub>(*t*) for time-step *j*.                                                                                                                                                                                                                                                                |
| *H*1                   | The noise Hamiltonian *H*<sub>1</sub>(*t*) for each noise realization at time-step *j*.                                                                                                                                                                                                                                       |
| *U*<sub>0</sub>                  | The system evolution matrix *U*<sub>0</sub>(*t*) in the absence of noise at time-step *j*.                                                                                                                                                                                                                                    |
| *U*<sub>*I*</sub>                  | The interaction unitary *U*<sub>*I*</sub>(*t*) for each noise realization at time-step *j*.                                                                                                                                                                                                                                     |
| *V*<sub>0</sub>                  | Set of 3 × 2000 expectation values (measurements) of the three Pauli observables for all possible states for each noise realization. For each state, the order of measurement is: *σ*<sub>*x*</sub>, *σ*<sub>*y*</sub>, *σ*<sub>*z*</sub> applied to the evolved initial states.                                                   |
| *E*<sub>0</sub>                  | The expectations values (measurements) of the three Pauli observables for all possible states averaged over all noise realizations. For each state, the order of measurement is: *σ*<sub>*x*</sub>, *σ*<sub>*y*</sub>, *σ*<sub>*z*</sub> applied to the evolved initial states.                                                           |


## QDataSet Generation

### Hardware specifications

Each dataset in the QDataSet consists of 10,000 examples. An example corresponds to a given control pulse sequence, associated with a set of noise realizations. Every dataset is stored as a compressed zip file, consisting of a number of Python *Pickle* files that stores the information. Each file is essentially a dictionary consisting of the elements described in the table below. The datasets were generated on the University of Technology (Sydney) high-performance computing cluster (iHPC). Each dataset was generated using Singularity containers with Python 3 installed, requiring standard packages including Tensorflow 2.5.0. 

The QDataSet was generated on using the iHPC Mars node (one of 30). The node consists of Intel Xeon Gold 6238R 2.2GHz 28cores (26 cores enabled) 38.5MB L3 Cache (Max Turbo Freq. 4.0GHz, Min 3.0GHz) 360GB RAM. We utilised GPU resources using a NVIDIA Quadro RTX 6000 Passive (3072 Cores, 384 Tensor Cores, 16GB Memory). It took around three months to generate over 2020-2021, coming to around 14TB of compressed quantum data. Single-qubit examples were relatively quick (between a few days and a week or so). The two-qubit examples took much longer, often several weeks.

### Simulation code

Links to the simulation code is set-out in Python scripts which can be found in the 'simulation' subfolder. To run a simulation, run the relevant code notebook. In more detail, the simulation code comrpises:
* *Dataset code*: each of the 52 datasets is generated in one of 26 Python scripts (each script generates the non-distorted and distored examples for the dataset). For example, the script 'dataset_G_1q_X.py' generates the single-qubit dataset with Gaussian control pulses via x-axis control (noise and distortion free)
* *utilities.py*: this script is called by each dataset code and contains general procedures for generating the dataset.
* *simulation.py*: this script is called by utilities.py and contains the details of the quantum simulation.

Please note, the two-qubit simulations tend to consume a lot of RAM. Using Singularity, wrapping a container with Python 3 and Tensorflow 2.5.0 required around 360GB of RAM running for between a few days and one week for most of the two-qubit simulation datasets.

## Dataset link and description

### Dataset Cloud storage

The QDataSet is stored using Cloudstor, a service provided via AARNet for UTS. We set-out the links below:

[QDataSet Cloudstor Link](https://cloudstor.aarnet.edu.au/plus/s/rxYKXBS7Tq0kB8o)

Each dataset is stored in its own separate subfolder. 

### Dataset description

The table below lists the name and description of each dataset.

| Dataset                   | Description                                                                                                                                                                          |
|----------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| G_1q_X                         | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: none; (iv) No distortion.                                                                                                     |
| G_1q_X_D                      | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: none; (iv) Distortion.                                                                                                        |
| G_1q_XY                         | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: none; (iv) No distortion.                                                                                                     |
| G_1q_XY_D                      | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: none; (iv) Distortion.                                                                                                        |
| G_1q_XY_XZ_N1N5              | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: N1 on x-axis, N5 on z-axis; (iv) No distortion.                                                              |
| G_1q_XY_XZ_N1N5_D           | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: N1 on x-axis, N5 on z-axis; (iv) No distortion.                                                              |
| G_1q_XY_XZ_N1N6              | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: N1 on x-axis, N6 on z-axis; (iv) Distortion.                                                                 |
| G_1q_XY_XZ_N1N6_D           | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: N1 on x-axis, N6 on z-axis; (iv) No distortion.                                                              |
| G_1q_XY_XZ_N3N6              | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: N1 on x-axis, N6 on z-axis; (iv) Distortion.                                                                 |
| G_1q_XY_XZ_N3N6_D           | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: N1 on x-axis, N6 on z-axis; (iv) No distortion.                                                              |
| G_1q_X_Z_N1                  | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N1 on z-axis; (iv) No distortion.                                                                                           |
| G_1q_X_Z_N1_D               | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N1 on z-axis; (iv) Distortion.                                                                                              |
| G_1q_X_Z_N2                  | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N2 on z-axis; (iv) No distortion.                                                                                           |
| G_1q_X_Z_N2_D               | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N2 on z-axis; (iv) Distortion.                                                                                              |
| G_1q_X_Z_N3                  | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N3 on z-axis; (iv) No distortion.                                                                                           |
| G_1q_X_Z_N3_D               | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N3 on z-axis; (iv) Distortion.                                                                                              |
| G_1q_X_Z_N4                  | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N4 on z-axis; (iv) No distortion.                                                                                           |
| G_1q_X_Z_N4_D               | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N4 on z-axis; (iv) Distortion.                                                                                              |
| G_2q_IX-XI_IZ-ZI_N1-N6       | (i) Qubits: two; (ii) Control: x-axis on both qubits, Gaussian; (iii)                                                                                                                       |
| G_2q_IX-XI_IZ-ZI_N1-N6_D    | (i) Qubits: two; (ii) Control: x-axis on both qubits, Gaussian; (iii) Noise: N1 and N6 z-axis on each qubit; (iv) Distortion.                                                             |
| G_2q_IX-XI-XX                  | (i) Qubits: two; (ii) Control: single x-axis control on both qubits and x-axis interacting control, Gaussian; (iii) Noise: none; (iv) No distortion.                                      |
| G_2q_IX-XI-XX_D               | (i) Qubits: two; (ii) Control: single x-axis control on both qubits and x-axis interacting control, Gaussian; (iii) Noise: none; (iv) Distortion.                                         |
| G_2q_IX-XI-XX_IZ-ZI_N1-N5    | (i) Qubits: two; (ii) Control: single x-axis control on both qubits and x-axis interacting control, Gaussian; (iii) Noise: N1 and N5 on z-axis noise on each qubit; (iv) No distortion. |
| G_2q_IX-XI-XX_IZ-ZI_N1-N5    | (i) Qubits: two; (ii) Control: single x-axis control on both qubits and x-axis interacting control, Gaussian; (iii) Noise: N1 and N5 on z-axis noise on each qubit; (iv) Distortion.    |
| S_1q_X                         | (i) Qubits: one; (ii) Control: x-axis, square; (iii) Noise: none; (iv) No distortion.                                                                                                       |
| S_1q_X_D                      | (i) Qubits: one; (ii) Control: x-axis, Gaussquaresian; (iii) Noise: none; (iv) Distortion.                                                                                                  |
| S_1q_XY                         | (i) Qubits: one; (ii) Control: x-axis and y-axis, square; (iii) Noise: none; (iv) No distortion.                                                                                                       |
| S_1q_XY_D                      | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussquaresian; (iii) Noise: none; (iv) Distortion.                                                                                                  |
| S_1q_XY_XZ_N1N5              | (i) Qubits: one; (ii) Control: x-axis and y-axis, square; (iii) Noise: N1 on x-axis, N5 on z-axis; (iv) No distortion.                                                                |
| S_1q_XY_XZ_N1N5_D           | (i) Qubits: one; (ii) Control: x-axis and y-axis, Gaussian; (iii) Noise: N1 on x-axis, N5 on z-axis; (iv) No distortion.                                                              |
| S_1q_XY_XZ_N1N6              | (i) Qubits: one; (ii) Control: x-axis and y-axis, square; (iii) Noise: N1 on x-axis, N6 on z-axis; (iv) Distortion.                                                                   |
| S_1q_XY_XZ_N1N6_D           | (i) Qubits: one; (ii) Control: x-axis and y-axis, square; (iii) Noise: N1 on x-axis, N6 on z-axis; (iv) No distortion.                                                                |
| S_1q_XY_XZ_N3N6              | (i) Qubits: one; (ii) Control: x-axis and y-axis, square; (iii) Noise: N1 on x-axis, N6 on z-axis; (iv) Distortion.                                                                   |
| S_1q_XY_XZ_N3N6_D           | (i) Qubits: one; (ii) Control: x-axis and y-axis, square; (iii) Noise: N1 on x-axis, N6 on z-axis; (iv) No distortion.                                                                |
| S_1q_X_Z_N1                  | (i) Qubits: one; (ii) Control: x-axis, square; (iii) Noise: N1 on z-axis; (iv) No distortion.                                                                                             |
| S_1q_X_Z_N1_D               | (i) Qubits: one; (ii) Control: x-axis, square; (iii) Noise: N1 on z-axis; (iv) Distortion.                                                                                                |
| S_1q_X_Z_N2                  | (i) Qubits: one; (ii) Control: x-axis, square; (iii) Noise: N2 on z-axis; (iv) No distortion.                                                                                             |
| G_1q_X_Z_N2_D               | (i) Qubits: one; (ii) Control: x-axis, Gaussian; (iii) Noise: N2 on z-axis; (iv) Distortion.                                                                                              |
| S_1q_X_Z_N3                  | (i) Qubits: one; (ii) Control: x-axis, square; (iii) Noise: N3 on z-axis; (iv) No distortion.                                                                                             |
| S_1q_X_Z_N3_D               | (i) Qubits: one; (ii) Control: x-axis, square; (iii) Noise: N3 on z-axis; (iv) Distortion.                                                                                                |
| S_1q_X_Z_N4                  | (i) Qubits: one; (ii) Control: x-axis, square; (iii) Noise: N4 on z-axis; (iv) No distortion.                                                                                             |
| S_1q_X_Z_N4_D               | (i) Qubits: one; (ii) Control: x-axis, square; (iii) Noise: N4 on z-axis; (iv) Distortion.                                                                                                |
| S_2q_IX-XI_IZ-ZI_N1-N6       | (i) Qubits: two; (ii) Control: x-axis on both qubits, square; (iii) Noise: N1 and N6 z-axis on each qubit; (iv) No distortion.                                                            |
| S_2q_IX-XI_IZ-ZI_N1-N6_D    | (i) Qubits: two; (ii) Control: x-axis on both qubits, square; (iii) Noise: N1 and N6 z-axis on each qubit; (iv) Distortion.                                                               |
| S_2q_IX-XI-XX                  | (i) Qubits: two; (ii) Control: single x-axis control on both qubits and x-axis interacting control, square; (iii) Noise: none; (iv) No distortion.                                        |
| S_2q_IX-XI-XX_D               | (i) Qubits: two; (ii) Control: single x-axis control on both qubits and x-axis interacting control, square; (iii) Noise: none; (iv) Distortion.                                           |
| S_2q_IX-XI-XX_IZ-ZI_N1-N5    | (i) Qubits: two; (ii) Control: x-axis on both qubits and x-axis interacting control, square; (iii) Noise: N1 and N5 z-axis on each qubit; (iv) No distortion.                           |
| S_2q_IX-XI-XX_IZ-ZI_N1-N5_D | (i) Qubits: two; (ii) Control: x-axis on both qubits and x-axis interacting control, square; (iii) Noise: N1 and N5 z-axis on each qubit; (iv) Distortion.                              |
| S_2q_IX-XI-XX_IZ-ZI_N1-N6    | (i) Qubits: two; (ii) Control: x-axis on both qubits and x-axis interacting control, square; (iii) Noise: N1 and N6 z-axis on each qubit; (iv) No distortion.                           |
| S_2q_IX-XI-XX_IZ-ZI_N1-N6_D | (i) Qubits: two; (ii) Control: x-axis on both qubits and x-axis interacting control, square; (iii) Noise: N1 and N6 z-axis on each qubit; (iv) Distortion.                              |



```python

```################################################################################
"""
This module implements a TF quantum simulator. It has these classes:
    Noise_Layer            : This is an inernal class for generation noise
    HamiltonianConstruction: This is an internal class for constructing Hamiltonians
    QuantumCell            : This is an internal class required for implementing time-ordered evolution
    QuantumEvolution       : This is an internal class to implement time-ordered quantum evolution
    QuantumMeasurement     : This is an internal class to model coupling losses at the output
    VoLayer                : This is an internal class to calculate the Vo operator using the interaction picture
    quantumTFsim           : This is the main class that defines machine learning model for the qubit 
"""
###############################################################################
# Preamble
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers,Model
from scipy.linalg import dft
from scipy.signal import cheby1
###############################################################################
class Noise_Layer(layers.Layer):
    """
    class for generating time-domain realizations of noise 
    """
    def __init__(self, T, M, K, profile, **kwargs):
        """
        class constructor

        T      : Total duration of the input signal 
        M      : Number of time steps
        K      : Number of realizations
        profile: Type of noise
        
        """
        super(Noise_Layer, self).__init__(**kwargs)

        # store class parameters
        self.T = T
        self.M = M
        self.K = K
        
        # define a vector of discrteized frequencies
        f = np.fft.fftfreq(M)*M/T 
    
        # define time step
        Ts = T/M
        
        # check the noise type, initialize required variables and define the correct "call" method
        if profile==0:   # No noise
            self.call = self.call_0
        elif profile==1: # PSD of 1/f + a bump
            alpha        = 1
            S_Z         = 1*np.array([(1/(fq+1)**alpha)*(fq<=15) + (1/16)*(fq>15) + np.exp(-((fq-30)**2)/50)/2 for fq in f[f>=0]])  
            self.P_temp = tf.constant( np.tile( np.reshape( np.sqrt(S_Z*M/Ts), (1,1,self.M//2) ), (1,self.K,1) ), dtype=tf.complex64)
            self.call = self.call_1
        elif profile==2: # Colored Gaussian Stationary Noise
            self.g      = 0.1
            self.color  = tf.ones([self.M//4, 1, 1], dtype=tf.float32 )
            self.call   = self.call_2
        elif profile==3: # Colored Gaussian Non-stationary Noise
            time_range  = [(0.5*T/M) + (j*T/M) for j in range(M)] 
            self.g      = 0.2
            self.color  = tf.ones([self.M//4, 1, 1], dtype=tf.float32 )
            self.non_stationary = tf.constant( np.reshape( 1-(np.abs(np.array(time_range)-0.5*T)*2), (1,M,1,1) ), dtype=tf.float32)
            self.call   = self.call_3
        elif profile==4: # Colored Non-Gaussian Non-stationary Noise
            time_range  = [(0.5*T/M) + (j*T/M) for j in range(M)] 
            self.g      = 0.01
            self.color  = tf.ones([self.M//4, 1, 1], dtype=tf.float32 )
            self.non_stationary = tf.constant( np.reshape( 1-(np.abs(np.array(time_range)-0.5*T)*2), (1,M,1,1) ), dtype=tf.float32)
            self.call   = self.call_4
        elif profile==5: # PSD of 1/f
            alpha       = 1
            S_Z         = 1*np.array([(1/(fq+1)**alpha) for fq in f[f>=0]])  
            self.P_temp = tf.constant( np.tile( np.reshape( np.sqrt(S_Z*M/Ts), (1,1,self.M//2) ), (1,self.K,1) ), dtype=tf.complex64)
            self.call   = self.call_1        
        elif profile==6: # correlated noise      
            self.g = 0.3
            self.call = self.call_6

        
    def call_0(self, inputs, training=False): # No noise
        """
        Method to generate type 0 noise
        
        """
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([self.M, self.K,1],dtype=np.int32))],0 )
        return tf.zeros(temp_shape, dtype=tf.float32)
    
    def call_1(self, inputs, training=False): # PSD of 1/f + a bump
        """
        Method to generate type 1 and type 5 noise
        
        """
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([1, 1],dtype=np.int32))],0 )
        P_temp     = tf.tile(self.P_temp, temp_shape)
 
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([self.K, self.M//2],dtype=np.int32))],0 )
        P_temp     = tf.multiply(P_temp, tf.exp(2*np.pi*1j* tf.cast(tf.random.uniform(temp_shape, dtype=tf.float32), dtype=tf.complex64) ) )
        
        noise      = tf.math.real( tf.signal.ifft( tf.concat( [P_temp, tf.reverse( tf.math.conj(P_temp), axis=tf.constant([2]) )], axis=2 ) ) )
        noise      = tf.transpose( tf.expand_dims(noise, axis=-1), perm=[0,2,1,3] )       
        
        return noise
    
    def call_2(self, inputs, training=False): # Colored Gaussian Stationary Noise
        """
        Method to generate type 2 noise
        
        """
        temp_shape = tf.concat( [self.K*tf.shape(inputs)[0:1], tf.constant(np.array([self.M+(self.M//4)-1,1],dtype=np.int32))],0 )
        noise      =  self.g * tf.nn.convolution( input=tf.random.normal(temp_shape), filters=self.color, padding="VALID")
        
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([self.K, self.M,1],dtype=np.int32))],0 )
        noise      = tf.transpose( tf.reshape( tf.transpose(noise, perm=[0,2,1]), temp_shape), perm=[0,2,1,3] )
        
        return noise
        
    def call_3(self, inputs, training=False): # Colored Gaussian Non-stationary Noise
        """
        Method to generate type 3 noise
        
        """
        temp_shape = tf.concat( [self.K*tf.shape(inputs)[0:1], tf.constant(np.array([self.M+(self.M//4)-1,1],dtype=np.int32))],0 )
        noise      =  self.g * tf.nn.convolution( input=tf.random.normal(temp_shape), filters=self.color, padding="VALID")
        
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([self.K, self.M,1],dtype=np.int32))],0 )
        noise      = tf.transpose( tf.reshape( tf.transpose(noise, perm=[0,2,1]), temp_shape), perm=[0,2,1,3] )
        
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([1,self.K,1],dtype=np.int32))],0 )
        non_stationary = tf.tile(self.non_stationary, temp_shape)
        
        return tf.multiply(noise, non_stationary)
    
    def call_4(self, inputs, training=False): # Colored Gaussian Non-stationary Noise
        """
        Method to generate type 4 noise
        
        """

        temp_shape = tf.concat( [self.K*tf.shape(inputs)[0:1], tf.constant(np.array([self.M+(self.M//4)-1,1],dtype=np.int32))],0 )
        noise      = tf.nn.convolution( input=tf.random.normal(temp_shape), filters=self.color, padding="VALID")
        
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([self.K, self.M,1],dtype=np.int32))],0 )
        noise      = tf.transpose( tf.reshape( tf.transpose(noise, perm=[0,2,1]), temp_shape), perm=[0,2,1,3] )
        
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([1,self.K,1],dtype=np.int32))],0 )
        non_stationary = tf.tile(self.non_stationary, temp_shape)

        return tf.square( tf.multiply(noise, non_stationary) )*self.g

    def call_6(self, inputs, training=False):  # correlated noise
        """
        Method to generate type 6 noise
        
        """
        return self.g*( tf.square(inputs) )
###############################################################################
class LTI_Layer(layers.Layer):
    """
    class for simulating the response of an LTI system
    """
    def __init__(self, T, M, **kwargs):
        """
        class constructor

        T  : Total duration of the input signal 
        M  : Number of time steps
        """
        super(LTI_Layer, self).__init__(**kwargs)

        #define filter coefficients
        num, den = cheby1(4,0.1,2*np.pi*20, analog=True)
        
        # define frequency vector
        f = np.reshape(np.fft.fftfreq(M)*M/T, (1,M))

        # evaluate the dft matrix
        F =  dft(M, 'sqrtn')
        
        # evaluate the numerator and denominator at each frequency 
        H_num = np.concatenate([(1j*2*np.pi*f)**s for s in range(len(num)-1,-1,-1)], axis=0)
        H_den = np.concatenate([(1j*2*np.pi*f)**s for s in range(len(den)-1,-1,-1)], axis=0)

        # evaluate the frequency response
        H = np.diag( (num@H_num) / (den@H_den) )
        
        # evaluate the full transformation and convert to a tensor of correct shape
        self.L = tf.constant( np.reshape( F.conj().T @ H @ F, (1,1,M,M) ), dtype=tf.complex64 )


    def call(self, inputs):
        """
        Method to evaluate the ouput of the layer which represents the response of the system to the input
        """

        # convert variables to complex
        x = tf.cast(tf.transpose(inputs, perm=[0,2,1,3]), tf.complex64)
        
        # repeat the transformation matrix
        temp_shape = tf.concat( [tf.shape(inputs)[0:1], tf.constant(np.array([1,1,1],dtype=np.int32))],0 )
        L = tf.tile( self.L, temp_shape )

        # apply the transformation
        y = tf.transpose( tf.math.real( tf.matmul(L , x) ), perm=[0,2,1,3])

        return y
###############################################################################
class SigGen(layers.Layer):
    """
    This class defines a custom tensorflow layer that generates a sequence of control pulse parameters
    
    """
    def __init__(self, T, M, n_max, waveform="Gaussian", **kwargs):
        """
        class constructor
        
        T             : Total time of evolution
        M             : Number of discrete time steps
        n_max         : Maximum number of control pulses in the sequence
        waveform      : Waveform shape can either be "Gaussian", "Square", or "Zero"
        """
        # we must call thus function for any tensorflow custom layer
        super(SigGen, self).__init__(**kwargs)
        
        # store the parameters
        self.n_max           = n_max
        self.T               = T
        self.M               = M    
        self.time_range      = tf.constant( np.reshape( [(0.5*T/M) + (j*T/M) for j in range(M)], (1,M,1,1) ) , dtype=tf.float32)

        if waveform=="Gaussian":
            self.call = self.call_Gaussian
        elif waveform=="Square":
            self.call = self.call_Square
        else:
            self.call = self.call_0
       
        # define the constant parmaters to shift the pulses correctly
        self.pulse_width = (0.5*self.T/self.n_max)
        
        self.a_matrix    = np.ones((self.n_max, self.n_max))
        self.a_matrix[np.triu_indices(self.n_max,1)] = 0
        self.a_matrix    = tf.constant(np.reshape(self.a_matrix,(1,self.n_max,self.n_max)), dtype=tf.float32)
        
        self.b_matrix    = np.reshape([idx + 0.5 for idx in range(self.n_max)], (1,self.n_max,1) ) * self.pulse_width
        self.b_matrix    = tf.constant(self.b_matrix, dtype=tf.float32)
          
    def call_Square(self, inputs, training=False):
        """
        Method to generate square pulses
        
        """
        # generate randomly the signal parameters
        temp_shape = tf.concat( [tf.shape(inputs)[0:1],tf.constant(np.array([1,1],dtype=np.int32))],0 )
        a_matrix   = tf.tile(self.a_matrix, temp_shape)
        b_matrix   = tf.tile(self.b_matrix, temp_shape)
        
        temp_shape = tf.concat( [tf.shape(inputs)[0:1],tf.constant(np.array([self.n_max,1],dtype=np.int32))],0 )     
        amplitude  = 100*tf.random.uniform(shape = temp_shape, minval=-1, maxval=1, dtype=tf.float32)
        position   = 0.5*self.pulse_width + tf.random.uniform(shape= temp_shape, dtype=tf.float32)*( ( (self.T - self.n_max*self.pulse_width)/(self.n_max+1) ) - 0.5*self.pulse_width)
        position   = tf.matmul(a_matrix, position) + b_matrix
        std        = self.pulse_width * tf.ones(temp_shape, dtype=tf.float32)
                
        # combine the parameters into one tensor
        signal_parameters = tf.concat([amplitude, position, std] , -1)
        
        # construct the signal
        temp_shape = tf.concat( [tf.shape(inputs)[0:1],tf.constant(np.array([1,1,1],dtype=np.int32))],0 )     
        time_range = tf.tile(self.time_range, temp_shape)
        tau   = [tf.reshape( tf.matmul(position[:,idx,:],  tf.ones([1,self.M]) ), (tf.shape(time_range)) ) for idx in range(self.n_max)]
        A     = [tf.reshape( tf.matmul(amplitude[:,idx,:], tf.ones([1,self.M]) ), (tf.shape(time_range)) ) for idx in range(self.n_max)]
        sigma = [tf.reshape( tf.matmul(std[:,idx,:]      , tf.ones([1,self.M]) ), (tf.shape(time_range)) ) for idx in range(self.n_max)]    
        signal = [tf.multiply(A[idx], tf.cast( tf.logical_and( tf.greater(time_range, tau[idx] - 0.5*sigma[idx]), tf.less(time_range, tau[idx]+0.5*sigma[idx])), tf.float32) ) for idx in range(self.n_max)]
        signal = tf.add_n(signal)
        
        return signal_parameters, signal
        
    def call_Gaussian(self, inputs, training=False):
        """
        Method to generate Gaussian pulses
        
        """
        
        # generate randomly the signal parameters
        temp_shape = tf.concat( [tf.shape(inputs)[0:1],tf.constant(np.array([1,1],dtype=np.int32))],0 )
        a_matrix    = tf.tile(self.a_matrix, temp_shape)
        b_matrix    = tf.tile(self.b_matrix, temp_shape)
        
        temp_shape = tf.concat( [tf.shape(inputs)[0:1],tf.constant(np.array([self.n_max,1],dtype=np.int32))],0 )     
        amplitude   = 100*tf.random.uniform(shape = temp_shape, minval=-1, maxval=1, dtype=tf.float32)
        position    = 0.5*self.pulse_width + tf.random.uniform(shape= temp_shape, dtype=tf.float32)*( ( (self.T - self.n_max*self.pulse_width)/(self.n_max+1) ) - 0.5*self.pulse_width)
        position    = tf.matmul(a_matrix, position) + b_matrix
        std         = self.pulse_width * tf.ones(temp_shape, dtype=tf.float32)/6
                
        # combine the parameters into one tensor
        signal_parameters = tf.concat([amplitude, position, std] , -1)

        # construct the signal
        temp_shape = tf.concat( [tf.shape(inputs)[0:1],tf.constant(np.array([1,1,1],dtype=np.int32))],0 )     
        time_range = tf.tile(self.time_range, temp_shape)
        tau   = [tf.reshape( tf.matmul(position[:,idx,:],  tf.ones([1,self.M]) ), (tf.shape(time_range)) ) for idx in range(self.n_max)]
        A     = [tf.reshape( tf.matmul(amplitude[:,idx,:], tf.ones([1,self.M]) ), (tf.shape(time_range)) ) for idx in range(self.n_max)]
        sigma = [tf.reshape( tf.matmul(std[:,idx,:]      , tf.ones([1,self.M]) ), (tf.shape(time_range)) ) for idx in range(self.n_max)]
        signal = [tf.multiply(A[idx], tf.exp( -0.5*tf.square(tf.divide(time_range - tau[idx], sigma[idx])) ) ) for idx in range(self.n_max)] 
        signal = tf.add_n(signal)
        
        return signal_parameters, signal
    
    def call_0(self, inputs, training=False):
        """
        Method to generate the zero pulse sequence [for free evolution analysis]
        """
        
        # construct zero signal 
        temp_shape = tf.concat( [tf.shape(inputs)[0:1],tf.constant(np.array([self.M,1,1],dtype=np.int32))],0 )
        signal     = tf.zeros(temp_shape, dtype=tf.float32)
        temp_shape = tf.concat( [tf.shape(inputs)[0:1],tf.constant(np.array([self.n_max,3],dtype=np.int32))],0 )
        signal_parameters = tf.zeros(temp_shape, dtype=tf.float32)
        
        return signal_parameters,signal 
###############################################################################
class HamiltonianConstruction(layers.Layer):
    """
    This class defines a custom tensorflow layer that takes the Hamiltonian parameters as input, and generates the
    Hamiltonain matrix as an output at each time step for each example in the batch
    """
    
    def __init__(self, dynamic_operators, static_operators, **kwargs):
        """
        Class constructor 
        
        dynamic_operators: a list of all operators that have time-varying coefficients
        static_operators : a list of all operators that have constant coefficients
        """
        
        self.dynamic_operators = [tf.constant(op, dtype=tf.complex64) for op in dynamic_operators]
        self.static_operators  = [tf.constant(op, dtype=tf.complex64) for op in static_operators]
        self.dim = dynamic_operators[0].shape[-1]   

        # this has to be called for any tensorflow custom layer
        super(HamiltonianConstruction, self).__init__(**kwargs)
    
    def call(self, inputs):
        """
        This method must be defined for any custom layer, it is where the calculations are done.   
        
        inputs: a tensor representing the inputs to the layer. This is passed automatically by tensorflow. 
        """ 

        H = []
        # loop over the strengths of all dynamic operators
        
        for idx_op, op in enumerate(self.dynamic_operators):

            # select the particular strength of the operator
            h = tf.cast(inputs[:,:,:,idx_op:idx_op+1] ,dtype=tf.complex64)

            # construct a tensor in the form of a row vector whose elements are [d1,d2,d3, 1,1], where d1, d2, and d3 correspond to the
            # number of examples, number of time steps of the input, and number of realizations
            temp_shape = tf.concat( [tf.shape(inputs)[0:3],tf.constant(np.array([1,1],dtype=np.int32))],0 )

            # add two extra dimensions for batch, time, and realization
            operator = tf.expand_dims(op,0)
            operator = tf.expand_dims(operator,0)
            operator = tf.expand_dims(operator,0)
            
            # repeat the pauli operators along the batch and time dimensions
            operator = tf.tile(operator, temp_shape)
            
            # repeat the pulse waveform to as dxd matrix
            temp_shape = tf.constant(np.array([1,1,1,self.dim,self.dim],dtype=np.int32))
            h = tf.expand_dims(h,-1)
            h = tf.tile(h, temp_shape)
            
            # Now multiply each operator with its corresponding strength element-wise and add to the list of Hamiltonians
            H.append( tf.multiply(operator, h) )
       
        # loop over the strengths of all static operators
        for op in self.static_operators:          
            # construct a tensor in the form of a row vector whose elements are [d1,d2,d3,1,1], where d1, d2, and d2 correspond to the
            # number of examples, number of time steps of the input, and number of realizations
            temp_shape = tf.concat( [tf.shape(inputs)[0:3],tf.constant(np.array([1,1],dtype=np.int32))],0 )

            # add two extra dimensions for batch and time
            operator = tf.expand_dims(op,0)
            operator = tf.expand_dims(operator,0)
            operator = tf.expand_dims(operator,0)
            
            # repeat the pauli operators along the batch and time dimensions
            operator = tf.tile(operator, temp_shape)
            
            # Now add to the list of Hamiltonians
            H.append( operator )
        
        # now add all componenents together
        H =  tf.add_n(H)
                            
        return H    
###############################################################################
class QuantumCell(layers.Layer):
    """
    This class defines a custom tensorflow layer that takes Hamiltonian as input, and produces one step forward propagator
    """
    
    def __init__(self, delta_T, **kwargs):
        """
        Class constructor.
        delta_T: time step for each propagator
        """  
        
        # here we define the time-step including the imaginary unit, so we can later use it directly with the expm function
        self.delta_T= tf.constant(delta_T*-1j, dtype=tf.complex64)

        # we must define this parameter for RNN cells
        self.state_size = [1]
        
        # we must call thus function for any tensorflow custom layer
        super(QuantumCell, self).__init__(**kwargs)

    def call(self, inputs, states):        
        """
        This method must be defined for any custom layer, it is where the calculations are done.   
        
        inputs: The tensor representing the input to the layer. This is passed automatically by tensorflow.
        states: The tensor representing the state of the cell. This is passed automatically by tensorflow.
        """         
        
        previous_output = states[0] 
        
        # evaluate -i*H*delta_T
        Hamiltonian = inputs * self.delta_T
        
        #evaluate U = expm(-i*H*delta_T)
        U = tf.linalg.expm( Hamiltonian )
        
        # accuamalte U to to the rest of the propagators
        new_output  = tf.matmul(U, previous_output)    
        
        return new_output, [new_output]
###############################################################################
class QuantumEvolution(layers.RNN):
    """
    This class defines a custom tensorflow layer that takes Hamiltonian as input, and produces the time-ordered evolution unitary as output
    """
    
    def __init__(self, delta_T, **kwargs):
        """
        Class constructor.
              
        delta_T: time step for each propagator
        """  
        
        # use the custom-defined QuantumCell as base class for the nodes
        cell = QuantumCell(delta_T)

        # we must call thus function for any tensorflow custom layer
        super(QuantumEvolution, self).__init__(cell,  **kwargs)
      
    def call(self, inputs):          
        """
        This method must be defined for any custom layer, it is where the calculations are done.   
        
        inputs: The tensor representing the input to the layer. This is passed automatically by tensorflow.
        """
        
        # define identity matrix with correct dimensions to be used as initial propagtor 
        dimensions = tf.shape(inputs)
        I          = tf.eye( dimensions[-1], batch_shape=[dimensions[0], dimensions[2]], dtype=tf.complex64 )
        
        return super(QuantumEvolution, self).call(inputs, initial_state=[I])         
###############################################################################    
class QuantumMeasurement(layers.Layer):
    """
    This class defines a custom tensorflow layer that takes the unitary as input, 
    and generates the measurement outcome probability as output
    """
    
    def __init__(self, initial_state, measurement_operator, **kwargs):
        """
        Class constructor
        
        initial_state       : The inital density matrix of the state before evolution.
        Measurement_operator: The measurement operator
        """          
        self.initial_state        = tf.constant(initial_state, dtype=tf.complex64)
        self.measurement_operator = tf.constant(measurement_operator, dtype=tf.complex64)
    
        # we must call thus function for any tensorflow custom layer
        super(QuantumMeasurement, self).__init__(**kwargs)
            
    def call(self, x): 
        """
        This method must be defined for any custom layer, it is where the calculations are done.   
        
        x: a tensor representing the inputs to the layer. This is passed automatically by tensorflow. 
        """ 
    
        # extract the different inputs of this layer which are the Vo and Uc
        Vo, Uc = x
        
        # construct a tensor in the form of a row vector whose elements are [d1,1,1,1], where d1 corresponds to the
        # number of examples of the input
        temp_shape = tf.concat( [tf.shape(Vo)[0:1],tf.constant(np.array([1,1,1],dtype=np.int32))],0 )

        # add an extra dimensions for the initial state and measurement tensors to represent batch and realization
        initial_state        = tf.expand_dims( tf.expand_dims(self.initial_state,0), 0)
        measurement_operator = tf.expand_dims( tf.expand_dims(self.measurement_operator,0), 0) 
        
        # repeat the initial state and measurment tensors along the batch dimensions
        initial_state        = tf.tile(initial_state, temp_shape )
        measurement_operator = tf.tile(measurement_operator, temp_shape)   
        
        # evolve the initial state using the propagator provided as input
        final_state = tf.matmul(tf.matmul(Uc, initial_state), Uc, adjoint_b=True )
        
        
        # tile along the realization axis
        temp_shape  = tf.concat( [tf.constant(np.array([1,],dtype=np.int32)), tf.shape(Vo)[1:2], tf.constant(np.array([1,1],dtype=np.int32))],0 )
        final_state = tf.tile(final_state, temp_shape)
        measurement_operator = tf.tile(measurement_operator, temp_shape)  

        # calculate the probability of the outcome
        expectation = tf.linalg.trace( tf.matmul( tf.matmul( Vo, final_state), measurement_operator) ) 
    
        return tf.expand_dims( tf.math.real(expectation), -1)
###############################################################################    
class VoLayer(layers.Layer):
    """
    This class defines a custom tensorflow layer that constructs the Vo operator using the interaction picture definition
    """
    
    def __init__(self, O, **kwargs):
        """
        Class constructor
        
        O: The observable to be measaured
        """
        # this has to be called for any tensorflow custom layer
        super(VoLayer, self).__init__(**kwargs)
    
        self.O = tf.constant(O, dtype=tf.complex64)         
        
    def call(self, x):
        """
        This method must be defined for any custom layer, it is where the calculations are done.   
        
        x: a tensor representing the inputs to the layer. This is passed automatically by tensorflow. 
        """ 
        
        # retrieve the two inputs: Uc and UI
        UI,Uc = x
        
        UI_tilde = tf.matmul(Uc, tf.matmul(UI,Uc, adjoint_b=True) )

        # expand the observable operator along batch and realizations axis
        O = tf.expand_dims(self.O, 0)
        O = tf.expand_dims(O, 0)
         
        temp_shape = tf.concat( [tf.shape(Uc)[0:2], tf.constant(np.array([1,1],dtype=np.int32))], 0 )
        O = tf.tile(O, temp_shape)

        # Construct Vo operator         
        VO = tf.matmul(O, tf.matmul( tf.matmul(UI_tilde,O, adjoint_a=True), UI_tilde) )

        return VO 
###############################################################################
class quantumTFsim():
    """
    This is the main class that defines machine learning model of the qubit.
    """    
      
    def __init__(self, T, M, dynamic_operators, static_operators, noise_operators, measurement_operators, initial_states, K=1, waveform="Gaussian", num_pulses=5, distortion=False, noise_profile=0):
        """
        Class constructor.

        T                : Evolution time
        M                : Number of time steps
        dynamic_operators: A list of arrays that represent the terms of the control Hamiltonian (that depend on pulses)
        static_operators : A list of arrays that represent the terms of the drifting Hamiltonian (that are constant)
        noise_operators  : A list of arrays that represent the terms of the classical noise Hamiltonians
        K                : Number of noise realizations
        waveform         : The type of waveform [either "Zero", "Square", or "Gaussian"]
        num_pulses       : Number of pulses per control sequence
        distortion       : True for simulating distortions, False for no distortions 
        noise_profile    : The type of noise, a value chosen from [0,1,2,4,5,6]
        """

        delta_T   = T/M
        self.time_range = [(0.5*T/M) + (j*T/M) for j in range(M)]
        
        # define a dummy input layer needed to generate the control pulses and noise
        dummy_input = layers.Input(shape=(1,))
        
        # define the custom tensorflow layer that generates the control pulses for each direction and concatente if neccesary
        if len(dynamic_operators)>1:
            pulses            = [SigGen(T, M, num_pulses, waveform)(dummy_input) for _ in dynamic_operators]
            pulse_parameters  = layers.Concatenate(axis=-1)([p[0] for p in pulses])
            pulse_time_domain = layers.Concatenate(axis=-1)([p[1] for p in pulses])
        else:
            pulse_parameters, pulse_time_domain = SigGen(T, M, num_pulses, waveform)(dummy_input) 

        if distortion==True:
            distorted_pulse_time_domain = LTI_Layer(T, M)(pulse_time_domain)
        else:
            distorted_pulse_time_domain = pulse_time_domain
       
        # define the custom tensorflow layer that generates the noise realizations in time-domain and concatente if neccesary
        if len(noise_operators)>1:
            noise = []
            for profile in noise_profile:
                if profile!=6: #uncorrelated along different directions
                    noise.append( Noise_Layer(T, M, K, profile)(dummy_input) )
                else:    #correlated with the prevu=ious direction
                    noise.append( Noise_Layer(T, M, K, profile)(noise[-1]) )               
            noise_time_domain = layers.Concatenate(axis=-1)(noise)     
        else:
            noise_time_domain = Noise_Layer(T, M, K, noise_profile[0])(dummy_input)              

        # define the custom tensorflow layer that constructs the H0 part of the Hamiltonian from parameters at each time step
        H0 = HamiltonianConstruction(dynamic_operators=dynamic_operators, static_operators=static_operators, name="H0")(distorted_pulse_time_domain)

        # define the custom tensorflow layer that constructs the H1 part of the Hamiltonian from parameters at each time step
        H1 = HamiltonianConstruction(dynamic_operators=noise_operators, static_operators=[], name="H1")(noise_time_domain)
            
        # define the custom tensorflow layer that constructs the time-ordered evolution of H0 
        U0 = QuantumEvolution(delta_T, return_sequences=True, name="U0")(H0)
    
        # define Uc which is U0(T)
        Uc = layers.Lambda(lambda u0: u0[:,-1,:,:,:], name="Uc")(U0)
        
        # define custom tensorflow layer to calculate HI
        U0_ext = layers.Lambda(lambda x: tf.tile(x, tf.constant([1,1,K,1,1], dtype=tf.int32) ) )(U0)
        HI     = layers.Lambda(lambda x: tf.matmul( tf.matmul(x[0],x[1], adjoint_a=True), x[0] ), name="HI" )([U0_ext, H1])
    
        # define the custom defined tensorflow layer that constructs the time-ordered evolution of HI
        UI = QuantumEvolution(delta_T, return_sequences=False, name="UI")(HI)
        
        # construct the Vo operators
        Uc_ext = layers.Lambda(lambda x: tf.tile(x, tf.constant([1,K,1,1], dtype=tf.int32) ) )(Uc)        
        Vo     = [VoLayer(O, name="V%d"%idx_O)([UI,Uc_ext]) for idx_O, O in enumerate(measurement_operators)]
        
        # add the custom defined tensorflow layer that calculates the measurement outcomes
        expectations = [
                [QuantumMeasurement(rho,X, name="rho%dM%d"%(idx_rho,idx_X))([Vo[idx_X],Uc]) for idx_X, X in enumerate(measurement_operators)]
                for idx_rho,rho in enumerate(initial_states)]
       
        # concatenate all the measurement outcomes
        expectations = layers.Concatenate(axis=-1)(sum(expectations, [] ))
        
        # define now the tensorflow model
        self.model   = Model( inputs = dummy_input, outputs = [pulse_parameters, pulse_time_domain, distorted_pulse_time_domain, noise_time_domain, H0, H1, U0, Uc, UI, expectations] + Vo )
        
        # print a summary of the model showing the layers and their connections
        self.model.summary()
    
    def simulate(self, simulator_inputs, batch_size = 1):
        """
        This method is for predicting the measurement outcomes using the trained model. Usually called after training.
        
        simulator inputs: A dummy numpy array of shape (number of examples to simulate, 1)
        
        batch_size:  The number of examples to process at each batch, chosen according to available memory
        
        returns a list of arrays representing H0,H1,U0,U0(T),VO,expectations respectively
        """        
        return self.model.predict(simulator_inputs, verbose=1, batch_size = batch_size)
############################################################################################################################################################

"""

utilities.py: This module inlcudes functions to generate noise and controls 

and generate the dataset by simulating the quantum system



"""

###############################################################################

#preample

import numpy as np

import pickle

from simulator import quantumTFsim

import zipfile    

import os

import time

###############################################################################

Pauli_operators   = [np.eye(2), np.array([[0.,1.],[1.,0.]]), np.array([[0.,-1j],[1j,0.]]), np.array([[1.,0.],[0.,-1.]])]

###############################################################################

def simulate(sim_parameters):

    """

    This function generates the dataset and stores it based on the simulation parameters passed as a dictionary

    

    """

    ###########################################################################

    # 1) Define the simulator



    simulator  = quantumTFsim(sim_parameters["T"], sim_parameters["M"], sim_parameters["dynamic_operators"], sim_parameters["static_operators"], sim_parameters["noise_operators"], sim_parameters["measurement_operators"], 

                              sim_parameters["initial_states"], sim_parameters["K"], sim_parameters["pulse_shape"], sim_parameters["num_pulses"], False,  sim_parameters["noise_profile"])

    

    fzip = zipfile.ZipFile("%s.zip"%sim_parameters["name"], mode='w', compression=zipfile.ZIP_DEFLATED)          

   

    # 2) Run the simulator for pulses without distortions and collect the results

    print("Running the simulation for pulses without distortion\n")

    for idx_batch in range(sim_parameters["num_ex"]//sim_parameters["batch_size"]):

    ###########################################################################

        print("Simulating and storing batch %d\n"%idx_batch)

        start = time.time()

        simulation_results               = simulator.simulate(np.zeros( (sim_parameters["batch_size"],1) ), batch_size = sim_parameters["batch_size"])

        sim_parameters["elapsed_time"]   = time.time()-start

        pulse_parameters, pulses, distorted_pulses, noise = simulation_results[0:4]

        H0, H1, U0, Uc, UI, expectations = simulation_results[4:10]

        Vo                               = simulation_results[10:]

        ###########################################################################

        # 4) Save the results in an external file and zip everything

        for idx_ex in range(sim_parameters["batch_size"]):          

            Results = {"sim_parameters"  : sim_parameters,

                       "pulse_parameters": pulse_parameters[idx_ex:idx_ex+1, :], 

                       "time_range"      : simulator.time_range,

                       "pulses"          : pulses[idx_ex:idx_ex+1, :],

                       "distorted_pulses": pulses[idx_ex:idx_ex+1,:],

                       "expectations"    : np.average( expectations[idx_ex:idx_ex+1, :], axis=1),

                       "Vo_operator"     : [np.average( V[idx_ex:idx_ex+1, :], axis=1) for V in Vo],

                       "noise"           : noise[idx_ex:idx_ex+1, :],      

                       "H0"              : H0[idx_ex:idx_ex+1, :],

                       "H1"              : H1[idx_ex:idx_ex+1, :],

                       "U0"              : U0[idx_ex:idx_ex+1, :],

                       "UI"              : UI[idx_ex:idx_ex+1, :],

                       "Vo"              : [V[idx_ex:idx_ex+1, :] for V in Vo],  

                       "Eo"              : expectations[idx_ex:idx_ex+1, :]

                       }

            # open a pickle file

            fname = "%s_ex_%d"%(sim_parameters["name"],idx_ex + idx_batch*sim_parameters["batch_size"])

            f = open(fname, 'wb')

            # save the results

            pickle.dump(Results, f, -1)

            # close the pickle file

            f.close()

            #add the file to zip folder

            fzip.write(fname)

            # remove the pickle file

            os.remove(fname)

    ###########################################################################

    # close the zip file

    fzip.close()

    os.system('cp %s.zip /projects/QuantumDS/%s.zip'%(sim_parameters["name"],sim_parameters["name"]))

    ###########################################################################

    # 3) Run the simulator for pulses with distortions and collect the results

    print("Running the simulation for pulses with distortion\n")

    simulator  = quantumTFsim(sim_parameters["T"], sim_parameters["M"], sim_parameters["dynamic_operators"], sim_parameters["static_operators"], sim_parameters["noise_operators"], sim_parameters["measurement_operators"], 

                              sim_parameters["initial_states"], sim_parameters["K"], sim_parameters["pulse_shape"], sim_parameters["num_pulses"], True,  sim_parameters["noise_profile"])

     

    fzip = zipfile.ZipFile("%s_D.zip"%sim_parameters["name"], mode='w', compression=zipfile.ZIP_DEFLATED)          

   

    for idx_batch in range(sim_parameters["num_ex"]//sim_parameters["batch_size"]):

    ###########################################################################

        print("Simulating and storing batch %d\n"%idx_batch)

        start                            = time.time()

        simulation_results               = simulator.simulate(np.zeros( (sim_parameters["batch_size"],1) ), batch_size = sim_parameters["batch_size"])

        sim_parameters["elapsed_time"]   = time.time()-start

        pulse_parameters, pulses, distorted_pulses, noise = simulation_results[0:4]

        H0, H1, U0, Uc, UI, expectations = simulation_results[4:10]

        Vo                               = simulation_results[10:]

        ###########################################################################

        # 4) Save the results in an external file and zip everything

        for idx_ex in range(sim_parameters["batch_size"]):          

            Results = {"sim_parameters"  : sim_parameters,

                       "pulse_parameters": pulse_parameters[idx_ex:idx_ex+1, :], 

                       "time_range"      : simulator.time_range,

                       "pulses"          : pulses[idx_ex:idx_ex+1, :],

                       "distorted_pulses": distorted_pulses[idx_ex:idx_ex+1,:],

                       "expectations"    : np.average( expectations[idx_ex:idx_ex+1, :], axis=1),

                       "Vo_operator"     : [np.average( V[idx_ex:idx_ex+1, :], axis=1) for V in Vo],

                       "noise"           : noise[idx_ex:idx_ex+1, :],      

                       "H0"              : H0[idx_ex:idx_ex+1, :],

                       "H1"              : H1[idx_ex:idx_ex+1, :],

                       "U0"              : U0[idx_ex:idx_ex+1, :],

                       "UI"              : UI[idx_ex:idx_ex+1, :],

                       "Vo"              : [V[idx_ex:idx_ex+1, :] for V in Vo],  

                       "Eo"              : expectations[idx_ex:idx_ex+1, :]

                       }

            # open a pickle file

            fname = "%s_D_ex_%d"%(sim_parameters["name"],idx_ex + idx_batch*sim_parameters["batch_size"])

            f = open(fname, 'wb')

            # save the results

            pickle.dump(Results, f, -1)

            # close the pickle file

            f.close()

            #add the file to zip folder

            fzip.write(fname)

            # remove the pickle file

            os.remove(fname)

    ###########################################################################

    # close the zip file

    fzip.close() 

    os.system('cp %s_D.zip /projects/QuantumDS/%s_D.zip'%(sim_parameters["name"],sim_parameters["name"]))

###############################################################################        

def CheckNoise(sim_parameters):

    """

    This function calculates the coherence measurements to check the noise behaviour, based on the simulation parameters passed as a dictionary

    

    """

    ###########################################################################

    # 1) Define the simulator

    simulator  = quantumTFsim(sim_parameters["T"], sim_parameters["M"], sim_parameters["dynamic_operators"], sim_parameters["static_operators"], sim_parameters["noise_operators"], sim_parameters["measurement_operators"], 

                              sim_parameters["initial_states"], sim_parameters["K"], "Zero", sim_parameters["num_pulses"], False,  sim_parameters["noise_profile"])

    ###########################################################################

    # 3) Run the simulator and collect the results

    print("Running the simulation\n")

    simulation_results               = simulator.simulate(np.zeros((1,)), batch_size = 1)

    H0, H1, U0, Uc, UI, expectations = simulation_results[4:10] 

    Vo                               = simulation_results[10:]

    Vo                               = [np.average( V, axis=1) for V in Vo]

    print("Analyzing results\n")

    print("Measurement are:")

    print( np.average( expectations, axis=1) )

    print("The Vo operators are:")

    print(Vo)

    print("The distance measures are:")

    print([np.linalg.norm( V[0,:]-np.eye(sim_parameters["dim"]) , 2) for V in Vo])
